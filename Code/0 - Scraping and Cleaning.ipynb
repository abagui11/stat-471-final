{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (4.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.11.1 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from tweepy) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.0.0 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib<2,>=1.0.0->tweepy) (3.1.1)\n",
      "Requirement already satisfied: praw in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (7.4.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from praw) (1.2.1)\n",
      "Requirement already satisfied: update-checker>=0.18 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from prawcore<3,>=2.1->praw) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ArpanBagui/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import praw\n",
    "import tweepy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import csv\n",
    "import psycopg2\n",
    "import yfinance as yf\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering funciton that cleans each set and adds price column\n",
    "def filter_df(df, data_type, coin_name, coin_ticker):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    df['date_scrape'] = pd.to_datetime(df['date_scrape'])\n",
    "   \n",
    "\n",
    "    if data_type == 'reddit':\n",
    "        df['subreddit'] = df['subreddit'].str.lower()\n",
    "        filtered_df = df[df['subreddit'] == coin_name]\n",
    "\n",
    "    if data_type == 'twitter':\n",
    "        df['user_name'] = df['user_name'].str.lower()\n",
    "        filtered_df = df[df['user_name'] == coin_name]\n",
    "\n",
    "    if data_type == 'youtube':\n",
    "        df['search_word'] = df['search_word'].str.lower()\n",
    "        filtered_df = df[df['search_word'] == coin_name]\n",
    "        \n",
    "    \n",
    "\n",
    "    # Query price data\n",
    "    coin_df = yf.download(coin_ticker, start=df['date_scrape'].min(), end=df['date_scrape'].max()).reset_index().drop(columns=['Open', 'High', 'Low', 'Adj Close', 'Volume'])\n",
    "    coin_df = coin_df.rename(columns = {'Date': 'date_scrape'})\n",
    "\n",
    "    # Merge \n",
    "    output_df = filtered_df.merge(coin_df, on='date_scrape', how = 'outer')\n",
    "    output_df = output_df.ffill()\n",
    "    \n",
    "    #Making sure dates are in order        \n",
    "    output_df = output_df.sort_values(by = ['date_scrape']).reset_index() \n",
    "    output_df = output_df.drop(['index'], axis=1)\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.4.0 of praw is outdated. Version 7.5.0 was released Sunday November 14, 2021.\n"
     ]
    }
   ],
   "source": [
    "# Access Reddit API \n",
    "reddit = praw.Reddit(client_id= \"ibh9FWjQqVYZYw\",                      # your client id\n",
    "                     client_secret= \"VeGeOHgpCN9SVSDsClpaR_IRWsCfiA\",  # your client secret\n",
    "                     user_agent= \"reddit_scraper\",                     # user agent (app) name\n",
    "                     username = \"asharm2949\",                          # your reddit username asharm2949\n",
    "                     password = \"aman-sharma2949\",                     # your reddit password\n",
    "                     check_for_async=False)               \n",
    "\n",
    "# Subreddit name and queries list to srape\n",
    "scrape_dict = {\n",
    "                'Bitcoin': ['btc', 'bitcoin'],\n",
    "                'ethereum': ['eth', 'ethereum'],\n",
    "                'litecoin': ['ltc', 'litecoin'],\n",
    "                'algorand': ['algo', 'algorand'],\n",
    "                'cardano': ['ada', 'cardano'],\n",
    "                'Tether': ['usdt', 'tether'],\n",
    "                'Ripple': ['xrp', 'ripple'],\n",
    "                'cosmosnetwork': ['atom', 'cosmos'],\n",
    "                'dot': ['dot', 'polkadot'],\n",
    "                'dogecoin': ['doge', 'dogecoin']\n",
    "}\n",
    "\n",
    "scrape_list = ['CryptoCurrency']\n",
    "\n",
    "# Helper function \n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reddit_mass(scrape_list):\n",
    "  \n",
    "  # Post data dictionary\n",
    "  post_dict = {\n",
    "      \"timestamp_scrape\" : [],  # timestamp of the scrape\n",
    "      \"date_scrape\" : [],       # date of the scrape    \n",
    "      \"timestamp_post\" : [],    # timestamp of the post\n",
    "      \"subreddit\": [],          # subreddit of the post\n",
    "      \"id\" : [],                # unique id of the post\n",
    "      \"title\" : [],             # title of the post\n",
    "      \"url\" : [],               # url of the post\n",
    "      \"body\" : [],              # the descriptionof post\n",
    "      \"score\" : [],             # number of upvotes of the post\n",
    "      \"upvote_ratio\": [],       # ratio of upvotes to total votes\n",
    "      \"num_comms\": [],          # the number of comments on the post\n",
    "  }\n",
    "\n",
    "  for subreddit in scrape_list:\n",
    "    posts = reddit.subreddit('CryptoCurrency').hot(limit=5000)\n",
    "    \n",
    "    for post in posts:\n",
    "      post_dict['timestamp_scrape'].append(pd.to_datetime(\"now\"))\n",
    "      post_dict['date_scrape'].append(dt.date.today())\n",
    "      post_dict[\"timestamp_post\"].append(post.created_utc)\n",
    "      post_dict[\"subreddit\"].append(post.subreddit)\n",
    "      post_dict[\"id\"].append(post.id)\n",
    "      post_dict[\"title\"].append(post.title)\n",
    "      post_dict[\"url\"].append(post.url)\n",
    "      post_dict[\"body\"].append(post.selftext)\n",
    "      post_dict[\"score\"].append(post.score)\n",
    "      post_dict[\"upvote_ratio\"].append(post.upvote_ratio)           \n",
    "      post_dict[\"num_comms\"].append(post.num_comments)\n",
    "\n",
    "  reddit_data_mass = pd.DataFrame(post_dict)\n",
    "  reddit_data_mass['timestamp_post'] = reddit_data_mass[\"timestamp_post\"].apply(get_date)\n",
    "\n",
    "  return reddit_data_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Twitter API\n",
    "CONSUMER_KEY = 'PqIOkmsFKDc8lIoSaDGf0Kcr0'\n",
    "CONSUMER_SECRET = '50kaIGjkmKSSFTKoFtte8j6vbR0CX7KPUDqB4oRhpW0k7zPuY4'\n",
    "ACCESS_TOKEN = '1347086178365829123-nDPxqMJfjuf9qgVqOUQ8A8LsfZw7pD'\n",
    "ACCESS_TOKEN_SECRET = 'gT0tbfA9Ca97GbyAwODU8W453sSxLPpNwv800PFpvnXYo'\n",
    "# Bearer Token = 'AAAAAAAAAAAAAAAAAAAAAPA%2BMwEAAAAAYYSYRh%2B8n9rbJaxva3Y%2FWqtOidU%3D5wukphfJfVhYaxG6HYIPF7nbEI0f5ShwXgs3U8ccIhTC16rSxL'\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape twitter\n",
    "def scrape_twitter(search_word, num_tweets):\n",
    "    \n",
    "  # Scrape tweets\n",
    "  tweets = tweepy.Cursor(api.search,\n",
    "                          q=search_word + \" -filter:retweets\",\n",
    "                          wait_on_rate_limit = True,\n",
    "                          wait_on_rate_limit_notify = True,\n",
    "                          lang=\"en\",\n",
    "                          count=num_tweets,\n",
    "                          since=dt.date.today()).items()\n",
    "\n",
    "  # Post data dictionary\n",
    "  post_dict = {\n",
    "      \n",
    "    \"timestamp_scrape\" : [],  # timestamp of the scrape\n",
    "    \"date_scrape\" : [],       # date of the scrape\n",
    "    \"timestamp_tweet\" : [],   # timestamp of the tweet\n",
    "    \"search_word\": [],        # requested query \n",
    "    \"tweet_id\" : [],          # id of tweet\n",
    "    \"user_name\": [],          # name of user who tweeted\n",
    "    \"user_location\": [],      # location of user \n",
    "    \"text\" : [],              # text of the tweet\n",
    "    \"retweet_count\": [],      # number of retweets\n",
    "    \"favorite_count\": []      # number of likes\n",
    "  }\n",
    "\n",
    "  # Collect a list of tweets\n",
    "  for tweet in tweets:\n",
    "    post_dict['timestamp_scrape'].append(pd.to_datetime(\"now\"))\n",
    "    post_dict['date_scrape'].append(dt.date.today())\n",
    "    post_dict[\"timestamp_tweet\"].append(tweet.created_at)\n",
    "    post_dict[\"search_word\"].append(search_word)\n",
    "    post_dict[\"tweet_id\"].append(tweet.id)    \n",
    "    post_dict[\"user_name\"].append(tweet.user.screen_name)       \n",
    "    post_dict[\"user_location\"].append(tweet.user.location)   \n",
    "    post_dict[\"text\"].append(tweet.text)\n",
    "    post_dict[\"retweet_count\"].append(tweet.retweet_count)\n",
    "    post_dict[\"favorite_count\"].append(tweet.favorite_count)\n",
    "\n",
    "  twitter_data = pd.DataFrame(post_dict)\n",
    "  return twitter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube queries to search\n",
    "youtube_query_list = ['stellar crypto', 'ripple', 'cosmos crypto', 'dot crypto', 'dogecoin',\n",
    "                      'bitcoin', 'ethereum', 'litecoin', 'algorand', 'cardano',\n",
    "                      'tezos', 'monero', 'dai crypto', 'filecoin', 'tron crypto',\n",
    "                      'eos crypto', 'chainlink']\n",
    "\n",
    "# Helper function (format numeric fields)\n",
    "def clean_youtube_data(input_df):\n",
    "\n",
    "    watching = pd.DataFrame(input_df['views'].str.find('watching'))\n",
    "    mask = (watching['views'] == -1)\n",
    "    df = input_df[mask].reset_index(drop = True)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # channel_subs\n",
    "            subs = row['channel_subs']\n",
    "            index_w = subs.find(\" \")\n",
    "            subs = subs[0:index_w]\n",
    "            real_subs = 0\n",
    "\n",
    "            if (subs[len(subs)-1] == \"M\"):\n",
    "                real_subs = int(1000000*float(subs[0:len(subs)-1]))\n",
    "\n",
    "            elif (subs[len(subs)-1] == \"K\"):\n",
    "                real_subs = int(1000*float(subs[0:len(subs)-1]))\n",
    "\n",
    "            else:\n",
    "                real_subs = int(subs)\n",
    "\n",
    "            df.iat[index, 4] = real_subs\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            # channel name\n",
    "            channel_name = row['channel_name']\n",
    "            channel_name = channel_name.replace('\\n', '')\n",
    "            channel_name = channel_name.strip()\n",
    "            df.iat[index, 3] = channel_name\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            # title\n",
    "            title = row['title']\n",
    "            title = title.replace('\\n', '')\n",
    "            title = title.strip()\n",
    "            df.iat[index, 5] = title\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            # date posted\n",
    "            date_posted = row['date_posted']\n",
    "            date_posted = date_posted.split()\n",
    "            date_posted = date_posted[-3] + \" \" + date_posted[-2] + \" \" + date_posted[-1]\n",
    "            date_posted = dt.datetime.strptime(date_posted, '%b %d, %Y').date()\n",
    "            df.iat[index, 6] = date_posted\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # num_views\n",
    "            views = row['views']\n",
    "\n",
    "            if ('watching' in views):\n",
    "                df = df.drop(index)\n",
    "                continue\n",
    "\n",
    "            index_w2 = views.find(\" \")\n",
    "            real_views = views[0:index_w2]\n",
    "            real_views = int(real_views.replace(\",\", ''))\n",
    "            df.iat[index, 9] = real_views\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # num_likes\n",
    "            likes = row['num_likes']\n",
    "            likes = likes.rstrip(' ')\n",
    "            index_w3 = likes.find(\"M\")\n",
    "            index_w4 = likes.find(\"K\")\n",
    "\n",
    "            if (index_w3 != -1):\n",
    "                likes = float(likes[0:index_w3])*1000000\n",
    "\n",
    "            elif (index_w4 != -1):\n",
    "                likes =float(likes[0:index_w4])*1000\n",
    "\n",
    "            df.iat[index, 11] = likes\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # num_dislikes\n",
    "        try:\n",
    "            dislikes = row['num_dislikes']\n",
    "            index_w5 = dislikes.find(\"M\")\n",
    "            index_w6 = dislikes.find(\"K\")\n",
    "\n",
    "            if (index_w5 != -1):\n",
    "                dislikes = float(dislikes[0:index_w5])*1000000\n",
    "\n",
    "            elif (index_w6 != -1):\n",
    "                dislikes = float(dislikes[0:index_w6])*1000\n",
    "            df.iat[index, 12] = dislikes\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # num_comments\n",
    "        try:\n",
    "            comments = row['num_comments']\n",
    "            comments = int(comments.replace(\",\",\"\"))\n",
    "            df.iat[index, 10] = comments\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            # description\n",
    "            description = row['description']\n",
    "            description = description.replace('\\n', '')\n",
    "            description = description.strip()\n",
    "            df.iat[index, 8] = description\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "# Scrape function (coin queries)\n",
    "def scrape_youtube(search_query_list, num_vids):\n",
    "    # Access URL to scrape\n",
    "    template_url = 'https://www.youtube.com/results?search_query={}&sp=CAMSBAgEEAE%253D'\n",
    "\n",
    "    # Post data dictionary\n",
    "    post_dict = {\n",
    "            \"timestamp_scrape\" : [],  # timestamp of scrape\n",
    "            \"date_scrape\": [],        # date of scrape\n",
    "            \"search_word\" : [],       # search query\n",
    "            \"channel_name\" : [],      # name of posting account\n",
    "            \"channel_subs\" : [],      # number of subscribers on posting account\n",
    "            \"title\": [],              # title of video\n",
    "            \"date_posted\" : [],       # date video was posted\n",
    "            \"url\": [],                # title of video\n",
    "            \"description\": [],        # description of video\n",
    "            \"views\": [],              # number of video views\n",
    "            \"num_comments\": [],       # number of video views\n",
    "            \"num_likes\": [],          # number of video likes\n",
    "            \"num_dislikes\": []        # number of video dislikes\n",
    "    }\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--disable-notifications\")\n",
    "    #chrome_options.add_argument(\"--headless\")\n",
    "    #chrome_options.add_argument(\"--disable-gpu\")\n",
    "    #chrome_options.add_argument('--no-sandbox')\n",
    "    #chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    #chrome_options.add_argument(\"--window-size=1920,1920\")\n",
    "    #chrome_options.add_argument(\"--mute-audio\")\n",
    "\n",
    "\n",
    "    for search_query in search_query_list:\n",
    "        url = template_url.format(search_query)\n",
    "        PATH = \"/Users/ArpanBagui/Documents/UPenn/Projects/CryptoDash/chromedriver\"\n",
    "        #driver = webdriver.Chrome(executable_path=PATH, options=chrome_options)\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        #driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Find ads in results\n",
    "        path = '//*[@id=\"ad-badge-container\"]/ytd-badge-supported-renderer/div/span'\n",
    "        ad_list= driver.find_elements_by_xpath(path)\n",
    "        num_ads = len(ad_list)\n",
    "        \n",
    "        #Variable that counts vid num\n",
    "        vid_count = 0\n",
    "        \n",
    "        for video in driver.find_elements_by_id('video-title')[num_ads:num_vids + num_ads]:\n",
    "            #Adding to vid count\n",
    "            vid_count += 1\n",
    "            \n",
    "            try:\n",
    "                video.click()\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'lxml')\n",
    "                \n",
    "            try:\n",
    "                post_dict['url'].append(video.get_attribute('href'))\n",
    "            except StaleElementReferenceException:\n",
    "                post_dict['url'].append('')\n",
    "\n",
    "            try:\n",
    "                post_dict['title'].append(video.get_attribute('text'))\n",
    "            except StaleElementReferenceException:\n",
    "                post_dict['title'].append('')\n",
    "\n",
    "            try:\n",
    "                #Variable that allows us to skip over previous channels (weird error with soup)\n",
    "                channel_index = vid_count*2 - 1\n",
    "                channel = soup.find_all('a', {\"class\" : \"yt-simple-endpoint style-scope yt-formatted-string\"})[channel_index].get_text()\n",
    "                post_dict['channel_name'].append(channel)\n",
    "\n",
    "            except TimeoutException:\n",
    "                post_dict['channel_name'].append('')\n",
    "\n",
    "            try:\n",
    "                subs = soup.findAll('yt-formatted-string', id = \"owner-sub-count\")[0].get_text()\n",
    "                post_dict['channel_subs'].append(subs)\n",
    "\n",
    "            except TimeoutException:\n",
    "                post_dict['channel_subs'].append('')\n",
    "\n",
    "                \n",
    "            try:\n",
    "                date_posted = soup.find_all('yt-formatted-string', {\"class\" : \"style-scope ytd-video-primary-info-renderer\"})[1].get_text()\n",
    "                post_dict['date_posted'].append(date_posted)\n",
    "\n",
    "            except TimeoutException:\n",
    "                post_dict['date_posted'].append('')\n",
    "\n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'view-count')))\n",
    "                post_dict['views'].append(driver.find_element_by_class_name('view-count').text)\n",
    "\n",
    "            except TimeoutException:\n",
    "                post_dict['views'].append(np.NaN)\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'count')))\n",
    "                num_comments = soup.find_all('h2', id = 'count')[0].get_text()\n",
    "                num_comments = num_comments.split()[0]\n",
    "                post_dict['num_comments'].append(num_comments)\n",
    "\n",
    "            except TimeoutException:\n",
    "                post_dict['num_comments'].append(np.NaN)\n",
    "                \n",
    "            except IndexError:\n",
    "                post_dict['num_comments'].append(np.NaN)\n",
    "\n",
    "            try:\n",
    "                likes = soup.findAll('yt-formatted-string', {\"class\" : \"style-scope ytd-toggle-button-renderer style-text\"})[1].get_text()\n",
    "                post_dict['num_likes'].append(likes)\n",
    "\n",
    "            except TimeoutException:\n",
    "                post_dict['num_likes'].append(np.NaN)\n",
    "\n",
    "            try:\n",
    "                dislikes = soup.findAll('yt-formatted-string', {\"class\" : \"style-scope ytd-toggle-button-renderer style-text\"})[2].get_text()\n",
    "                post_dict['num_dislikes'].append(dislikes)\n",
    "            except TimeoutException:\n",
    "                post_dict['num_dislikes'].append(np.NaN)\n",
    "\n",
    "            try:\n",
    "                description = soup.find_all('div', id = 'description')[0].get_text() \n",
    "                post_dict['description'].append(description)\n",
    "\n",
    "            except TimeoutException:\n",
    "                post_dict['description'].append('')\n",
    "\n",
    "            post_dict['timestamp_scrape'].append(pd.to_datetime('now'))\n",
    "            post_dict['date_scrape'].append(dt.date.today())\n",
    "            post_dict['search_word'].append(search_query)\n",
    "\n",
    "            driver.back()\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "   \n",
    "    youtube_data = clean_youtube_data(pd.DataFrame(post_dict))\n",
    "\n",
    "    youtube_data['channel_subs'] = youtube_data['channel_subs'].replace([''], np.NaN)\n",
    "\n",
    "    youtube_data['views'] = youtube_data['views'].replace([''], np.NaN)\n",
    "    youtube_data['num_comments'] = youtube_data['num_comments'].replace([''], np.NaN)\n",
    "\n",
    "    youtube_data['num_comments_found'] = (youtube_data['num_comments'] > 0)\n",
    "\n",
    "\n",
    "    return youtube_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above scrapers have been running since March 2021, they are stored on a AWS server. The below code is collecting the data from the server and cleaning it so it can be used for our project. Since youtube stops in April, we only use the twitter and reddit data from March 2021 to April 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Datagrip (PostgreSQL) connection\n",
    "PASSWORD = \"postgres://myoaykflycsnkv:201a55285e96b40152f4865716b479ed9ee7ee4bbfc9ea28cab50cab5b66412c@ec2-54-90-13-87.compute-1.amazonaws.com:5432/d9hthb6b0r501d\"\n",
    "conn = psycopg2.connect(PASSWORD)\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_scrape</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_subs</th>\n",
       "      <th>num_comms</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>unique_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>eos</td>\n",
       "      <td>96375.0</td>\n",
       "      <td>8.656000</td>\n",
       "      <td>32.196000</td>\n",
       "      <td>0.953040</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>1185133.0</td>\n",
       "      <td>95.643145</td>\n",
       "      <td>333.832661</td>\n",
       "      <td>0.822823</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>filecoin</td>\n",
       "      <td>14418.0</td>\n",
       "      <td>11.596708</td>\n",
       "      <td>13.072016</td>\n",
       "      <td>0.850247</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>litecoin</td>\n",
       "      <td>353203.0</td>\n",
       "      <td>70.443548</td>\n",
       "      <td>109.465726</td>\n",
       "      <td>0.904536</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>MakerDAO</td>\n",
       "      <td>32265.0</td>\n",
       "      <td>9.700405</td>\n",
       "      <td>13.751012</td>\n",
       "      <td>0.896255</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>Monero</td>\n",
       "      <td>245692.0</td>\n",
       "      <td>59.948980</td>\n",
       "      <td>93.730612</td>\n",
       "      <td>0.913776</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>Ripple</td>\n",
       "      <td>341323.0</td>\n",
       "      <td>53.345382</td>\n",
       "      <td>124.734940</td>\n",
       "      <td>0.922309</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>Stellar</td>\n",
       "      <td>208828.0</td>\n",
       "      <td>44.734000</td>\n",
       "      <td>80.530000</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>tezos</td>\n",
       "      <td>65907.0</td>\n",
       "      <td>18.792000</td>\n",
       "      <td>66.482000</td>\n",
       "      <td>0.938540</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>Tronix</td>\n",
       "      <td>121302.0</td>\n",
       "      <td>21.401606</td>\n",
       "      <td>23.618474</td>\n",
       "      <td>0.899659</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_scrape subreddit  subreddit_subs  num_comms       score  \\\n",
       "4678  2021-12-18       eos         96375.0   8.656000   32.196000   \n",
       "4679  2021-12-18  ethereum       1185133.0  95.643145  333.832661   \n",
       "4680  2021-12-18  filecoin         14418.0  11.596708   13.072016   \n",
       "4681  2021-12-18  litecoin        353203.0  70.443548  109.465726   \n",
       "4682  2021-12-18  MakerDAO         32265.0   9.700405   13.751012   \n",
       "4683  2021-12-18    Monero        245692.0  59.948980   93.730612   \n",
       "4684  2021-12-18    Ripple        341323.0  53.345382  124.734940   \n",
       "4685  2021-12-18   Stellar        208828.0  44.734000   80.530000   \n",
       "4686  2021-12-18     tezos         65907.0  18.792000   66.482000   \n",
       "4687  2021-12-18    Tronix        121302.0  21.401606   23.618474   \n",
       "\n",
       "      upvote_ratio  unique_posts  \n",
       "4678      0.953040           500  \n",
       "4679      0.822823           496  \n",
       "4680      0.850247           486  \n",
       "4681      0.904536           496  \n",
       "4682      0.896255           494  \n",
       "4683      0.913776           490  \n",
       "4684      0.922309           498  \n",
       "4685      0.939600           500  \n",
       "4686      0.938540           500  \n",
       "4687      0.899659           498  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reddit pull code\n",
    "sql_reddit_query = \"\"\"\n",
    "    SELECT date_scrape, subreddit, AVG(subreddit_subs) AS subreddit_subs, AVG(num_comms) AS num_comms, AVG(score) AS score, AVG(upvote_ratio) AS upvote_ratio, COUNT(id) AS unique_posts\n",
    "    FROM reddit_df\n",
    "    GROUP BY subreddit, date_scrape\n",
    "    ORDER BY date_scrape\n",
    "    \"\"\"\n",
    "\n",
    "reddit_df = pd.read_sql_query(sql_reddit_query, conn)\n",
    "reddit_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving raw data\n",
    "reddit_df.to_csv('reddit_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_scrape</th>\n",
       "      <th>user_name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>account_followers</th>\n",
       "      <th>unique_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>cosmos</td>\n",
       "      <td>37.200000</td>\n",
       "      <td>191.600000</td>\n",
       "      <td>2.736170e+05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>Polkadot</td>\n",
       "      <td>45.600000</td>\n",
       "      <td>290.700000</td>\n",
       "      <td>1.017723e+06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>Algorand</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>97.700000</td>\n",
       "      <td>2.082450e+05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>StellarOrg</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>191.500000</td>\n",
       "      <td>7.070440e+05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>299.300000</td>\n",
       "      <td>1451.400000</td>\n",
       "      <td>4.046669e+06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>chainlink</td>\n",
       "      <td>48.600000</td>\n",
       "      <td>245.400000</td>\n",
       "      <td>6.684910e+05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>dogecoin</td>\n",
       "      <td>933.400000</td>\n",
       "      <td>5259.600000</td>\n",
       "      <td>2.692695e+06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>monero</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>4.605760e+05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>Cardano</td>\n",
       "      <td>161.500000</td>\n",
       "      <td>977.333333</td>\n",
       "      <td>1.176385e+06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>LTCFoundation</td>\n",
       "      <td>16.222222</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>2.056123e+05</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_scrape      user_name  retweet_count  favorite_count  \\\n",
       "4017  2021-12-18         cosmos      37.200000      191.600000   \n",
       "4018  2021-12-18       Polkadot      45.600000      290.700000   \n",
       "4019  2021-12-18       Algorand      15.700000       97.700000   \n",
       "4020  2021-12-18     StellarOrg      45.500000      191.500000   \n",
       "4021  2021-12-18        Bitcoin     299.300000     1451.400000   \n",
       "4022  2021-12-18      chainlink      48.600000      245.400000   \n",
       "4023  2021-12-18       dogecoin     933.400000     5259.600000   \n",
       "4024  2021-12-18         monero      29.400000      126.500000   \n",
       "4025  2021-12-18        Cardano     161.500000      977.333333   \n",
       "4026  2021-12-18  LTCFoundation      16.222222       72.333333   \n",
       "\n",
       "      account_followers  unique_users  \n",
       "4017       2.736170e+05            10  \n",
       "4018       1.017723e+06            10  \n",
       "4019       2.082450e+05            10  \n",
       "4020       7.070440e+05            10  \n",
       "4021       4.046669e+06            10  \n",
       "4022       6.684910e+05            10  \n",
       "4023       2.692695e+06            10  \n",
       "4024       4.605760e+05            10  \n",
       "4025       1.176385e+06             6  \n",
       "4026       2.056123e+05             9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Twitter pull code\n",
    "sql_twitter_query = \"\"\"\n",
    "    SELECT date_scrape, user_name, AVG(retweet_count) AS retweet_count, AVG(favorite_count) AS favorite_count, AVG(account_followers) AS account_followers, COUNT(tweet_id) AS unique_users\n",
    "    FROM twitter_df\n",
    "    GROUP BY user_name, date_scrape\n",
    "    ORDER BY date_scrape\n",
    "\"\"\"\n",
    "\n",
    "twitter_df = pd.read_sql_query(sql_twitter_query, conn)\n",
    "twitter_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving raw data\n",
    "twitter_df.to_csv('twitter_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_scrape</th>\n",
       "      <th>search_word</th>\n",
       "      <th>channel_subs</th>\n",
       "      <th>views</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_likes</th>\n",
       "      <th>unique_channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>dai crypto</td>\n",
       "      <td>7.061200e+03</td>\n",
       "      <td>1.839500e+03</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>131.700000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>algorand</td>\n",
       "      <td>2.460833e+04</td>\n",
       "      <td>1.137183e+04</td>\n",
       "      <td>155.600000</td>\n",
       "      <td>518.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>cardano</td>\n",
       "      <td>5.231667e+05</td>\n",
       "      <td>1.803102e+05</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>9216.666667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>eos crypto</td>\n",
       "      <td>1.827125e+05</td>\n",
       "      <td>8.741700e+04</td>\n",
       "      <td>1068.400000</td>\n",
       "      <td>5286.166667</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>tezos</td>\n",
       "      <td>5.413600e+04</td>\n",
       "      <td>1.534120e+04</td>\n",
       "      <td>165.625000</td>\n",
       "      <td>1129.400000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>cosmos crypto</td>\n",
       "      <td>2.031000e+05</td>\n",
       "      <td>6.753020e+04</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>3210.300000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>ripple</td>\n",
       "      <td>3.785933e+05</td>\n",
       "      <td>1.391253e+06</td>\n",
       "      <td>693.285714</td>\n",
       "      <td>22890.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>litecoin</td>\n",
       "      <td>4.770889e+05</td>\n",
       "      <td>8.732240e+04</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>3936.400000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>dogecoin</td>\n",
       "      <td>1.806033e+06</td>\n",
       "      <td>3.897848e+05</td>\n",
       "      <td>1453.600000</td>\n",
       "      <td>17088.888889</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>1.051933e+06</td>\n",
       "      <td>3.555055e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14833.333333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_scrape    search_word  channel_subs         views  num_comments  \\\n",
       "671  2021-04-28     dai crypto  7.061200e+03  1.839500e+03     22.500000   \n",
       "672  2021-04-28       algorand  2.460833e+04  1.137183e+04    155.600000   \n",
       "673  2021-04-28        cardano  5.231667e+05  1.803102e+05   1283.000000   \n",
       "674  2021-04-28     eos crypto  1.827125e+05  8.741700e+04   1068.400000   \n",
       "675  2021-04-28          tezos  5.413600e+04  1.534120e+04    165.625000   \n",
       "676  2021-04-28  cosmos crypto  2.031000e+05  6.753020e+04    609.000000   \n",
       "677  2021-04-28         ripple  3.785933e+05  1.391253e+06    693.285714   \n",
       "678  2021-04-28       litecoin  4.770889e+05  8.732240e+04    517.000000   \n",
       "679  2021-04-28       dogecoin  1.806033e+06  3.897848e+05   1453.600000   \n",
       "680  2021-04-28       ethereum  1.051933e+06  3.555055e+05      0.000000   \n",
       "\n",
       "        num_likes  unique_channels  \n",
       "671    131.700000               10  \n",
       "672    518.500000                6  \n",
       "673   9216.666667                6  \n",
       "674   5286.166667                8  \n",
       "675   1129.400000               10  \n",
       "676   3210.300000               10  \n",
       "677  22890.000000               10  \n",
       "678   3936.400000               10  \n",
       "679  17088.888889                9  \n",
       "680  14833.333333                6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Youtube Pull Code\n",
    "sql_youtube_query = \"\"\"\n",
    "    SELECT date_scrape, search_word, AVG(channel_subs) AS channel_subs, AVG(views) AS views, AVG(num_comments) AS num_comments, AVG(num_likes) AS num_likes, COUNT(channel_name) AS unique_channels \n",
    "    FROM youtube_df\n",
    "    GROUP BY search_word, date_scrape\n",
    "    ORDER BY date_scrape\n",
    "\"\"\"\n",
    "\n",
    "youtube_df = pd.read_sql_query(sql_youtube_query, conn)\n",
    "youtube_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving raw data\n",
    "youtube_df.to_csv('youtube_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling bitcoin data\n",
    "reddit_bitcoin = filter_df(reddit_df, 'reddit', 'bitcoin', 'BTC-USD')\n",
    "twitter_bitcoin = filter_df(twitter_df, 'twitter', 'bitcoin', 'BTC-USD')\n",
    "youtube_bitcoin = filter_df(youtube_df, 'youtube', 'bitcoin', 'BTC-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling ethereum data\n",
    "reddit_ethereum = filter_df(reddit_df, 'reddit', 'ethereum', 'ETH-USD')\n",
    "twitter_ethereum = filter_df(twitter_df, 'twitter', 'ethereum', 'ETH-USD')\n",
    "youtube_ethereum = filter_df(youtube_df, 'youtube', 'ethereum', 'ETH-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling cardano data\n",
    "reddit_cardano = filter_df(reddit_df, 'reddit', 'cardano', 'ADA-USD')\n",
    "twitter_cardano = filter_df(twitter_df, 'twitter', 'cardano', 'ADA-USD')\n",
    "youtube_cardano = filter_df(youtube_df, 'youtube', 'cardano', 'ADA-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling ripple data\n",
    "reddit_ripple = filter_df(reddit_df, 'reddit', 'ripple', 'XRP-USD')\n",
    "twitter_ripple = filter_df(twitter_df, 'twitter', 'ripple', 'XRP-USD')\n",
    "youtube_ripple = filter_df(youtube_df, 'youtube', 'ripple', 'XRP-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling algorand data\n",
    "reddit_algorand = filter_df(reddit_df, 'reddit', 'algorand', 'ALGO-USD')\n",
    "twitter_algorand = filter_df(twitter_df, 'twitter', 'algorand', 'ALGO-USD')\n",
    "youtube_algorand = filter_df(youtube_df, 'youtube', 'algorand', 'ALGO-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling dogecoin data\n",
    "reddit_doge = filter_df(reddit_df, 'reddit', 'dogecoin', 'DOGE-USD')\n",
    "twitter_doge = filter_df(twitter_df, 'twitter', 'dogecoin', 'DOGE-USD')\n",
    "youtube_doge = filter_df(youtube_df, 'youtube', 'dogecoin', 'DOGE-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling chainlink data\n",
    "reddit_link = filter_df(reddit_df, 'reddit', 'chainlink', 'LINK-USD')\n",
    "twitter_link = filter_df(twitter_df, 'twitter', 'chainlink', 'LINK-USD')\n",
    "youtube_link = filter_df(youtube_df, 'youtube', 'chainlink', 'LINK-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling monero data\n",
    "reddit_monero = filter_df(reddit_df, 'reddit', 'monero', 'XMR-USD')\n",
    "twitter_monero = filter_df(twitter_df, 'twitter', 'monero', 'XMR-USD')\n",
    "youtube_monero = filter_df(youtube_df, 'youtube', 'monero', 'XMR-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling filecoin data\n",
    "reddit_filecoin = filter_df(reddit_df, 'reddit', 'filecoin', 'FIL-USD')\n",
    "twitter_filecoin = filter_df(twitter_df, 'twitter', 'filecoin', 'FIL-USD')\n",
    "youtube_filecoin = filter_df(youtube_df, 'youtube', 'filecoin', 'FIL-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling litecoin data\n",
    "reddit_litecoin = filter_df(reddit_df, 'reddit', 'litecoin', 'LTC-USD')\n",
    "twitter_litecoin = filter_df(twitter_df, 'twitter', 'litecoin', 'LTC-USD')\n",
    "youtube_litecoin = filter_df(youtube_df, 'youtube', 'litecoin', 'LTC-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling tezos data\n",
    "reddit_tezos = filter_df(reddit_df, 'reddit', 'tezos', 'XTZ-USD')\n",
    "twitter_tezos = filter_df(twitter_df, 'twitter', 'tezos', 'XTZ-USD')\n",
    "youtube_tezos = filter_df(youtube_df, 'youtube', 'tezos', 'XTZ-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Compiling stellar data\n",
    "reddit_stellar = filter_df(reddit_df, 'reddit', 'stellar', 'XLM-USD')\n",
    "twitter_stellar = filter_df(twitter_df, 'twitter', 'stellarorg', 'XLM-USD')\n",
    "youtube_stellar = filter_df(youtube_df, 'youtube', 'stellar crypto', 'XLM-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating overall reddit df\n",
    "reddit_dfs = [reddit_bitcoin, reddit_ethereum, reddit_cardano, reddit_ripple, reddit_algorand, reddit_doge, reddit_link, reddit_monero, reddit_filecoin, reddit_litecoin, reddit_tezos, reddit_stellar]\n",
    "reddit_clean = pd.concat(reddit_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating overall twitter df\n",
    "twitter_dfs = [twitter_bitcoin, twitter_ethereum, twitter_cardano, twitter_ripple, twitter_algorand, twitter_doge, twitter_link, twitter_monero, twitter_filecoin, twitter_litecoin, twitter_tezos, twitter_stellar]\n",
    "twitter_clean = pd.concat(twitter_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating overall youtube df\n",
    "youtube_dfs = [youtube_bitcoin, youtube_ethereum, youtube_cardano, youtube_ripple, youtube_algorand, youtube_doge, youtube_link, youtube_monero, youtube_filecoin, youtube_litecoin, youtube_tezos, youtube_stellar]\n",
    "youtube_clean = pd.concat(youtube_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating overall df by combining reddit and youtube\n",
    "df_final = pd.merge(reddit_clean, youtube_clean, how=\"right\", on=\"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding twitter to final\n",
    "df_final = pd.merge(df_final, twitter_clean, how=\"right\", on=\"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing cols we want\n",
    "cols = ['date_scrape', 'subreddit', 'subreddit_subs', 'num_comms', 'score', 'upvote_ratio', 'unique_posts', 'retweet_count',\n",
    "       'favorite_count', 'account_followers', 'unique_users', 'channel_subs', 'views', 'num_comments', 'num_likes',\n",
    "       'unique_channels', 'Close']\n",
    "df_final = df_final[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping nans\n",
    "df_final = df_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "df_final = df_final.rename(columns={\"subreddit\": \"coin_name\", \"subreddit_subs\": \"r_subscribers\", \"num_comms\": \"r_comments\",\n",
    "                        \"score\" : \"r_upvotes\", \"upvote_ratio\" : \"r_upvote_ratio\", \"unique_posts\" : \"t_unique_posts\",\n",
    "                        \"retweet_count\" : \"t_retweets\", \"favorite_count\" : \"t_favorites\", \"account_followers\" : \"t_followers\",\n",
    "                        \"unique_users\" : \"t_unique_users\", \"channel_subs\" : \"y_subscribers\", \"views\" : \"y_views\", \"num_comments\" : \"y_comments\",\n",
    "                        \"num_likes\" : \"y_likes\", \"unique_channels\" : \"y_unique_channels\", \"Close\" : \"price\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_scrape</th>\n",
       "      <th>coin_name</th>\n",
       "      <th>r_subscribers</th>\n",
       "      <th>r_comments</th>\n",
       "      <th>r_upvotes</th>\n",
       "      <th>r_upvote_ratio</th>\n",
       "      <th>t_unique_posts</th>\n",
       "      <th>t_retweets</th>\n",
       "      <th>t_favorites</th>\n",
       "      <th>t_followers</th>\n",
       "      <th>t_unique_users</th>\n",
       "      <th>y_subscribers</th>\n",
       "      <th>y_views</th>\n",
       "      <th>y_comments</th>\n",
       "      <th>y_likes</th>\n",
       "      <th>y_unique_channels</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2557418.0</td>\n",
       "      <td>190.953722</td>\n",
       "      <td>1351.696177</td>\n",
       "      <td>0.925111</td>\n",
       "      <td>497.0</td>\n",
       "      <td>434.166667</td>\n",
       "      <td>2812.666667</td>\n",
       "      <td>1631642.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.845257e+06</td>\n",
       "      <td>9.898475e+05</td>\n",
       "      <td>5160.111111</td>\n",
       "      <td>833.700000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54824.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2561723.0</td>\n",
       "      <td>192.705645</td>\n",
       "      <td>1384.280242</td>\n",
       "      <td>0.926613</td>\n",
       "      <td>496.0</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>2691.400000</td>\n",
       "      <td>1639941.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.918453e+06</td>\n",
       "      <td>1.450209e+06</td>\n",
       "      <td>5807.250000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56008.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2565734.0</td>\n",
       "      <td>194.002016</td>\n",
       "      <td>1391.931452</td>\n",
       "      <td>0.927359</td>\n",
       "      <td>496.0</td>\n",
       "      <td>416.600000</td>\n",
       "      <td>2967.400000</td>\n",
       "      <td>1650183.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.920220e+06</td>\n",
       "      <td>1.487169e+06</td>\n",
       "      <td>3382.600000</td>\n",
       "      <td>768.333333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>57805.121094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2569574.0</td>\n",
       "      <td>197.231855</td>\n",
       "      <td>1419.247984</td>\n",
       "      <td>0.929335</td>\n",
       "      <td>496.0</td>\n",
       "      <td>424.800000</td>\n",
       "      <td>2999.100000</td>\n",
       "      <td>1656158.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.760500e+06</td>\n",
       "      <td>1.116006e+06</td>\n",
       "      <td>4232.400000</td>\n",
       "      <td>689.800000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57332.089844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2574583.0</td>\n",
       "      <td>199.645161</td>\n",
       "      <td>1462.635081</td>\n",
       "      <td>0.928972</td>\n",
       "      <td>496.0</td>\n",
       "      <td>727.500000</td>\n",
       "      <td>4924.400000</td>\n",
       "      <td>1667004.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.613264e+06</td>\n",
       "      <td>1.144156e+06</td>\n",
       "      <td>3619.000000</td>\n",
       "      <td>670.900000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>61243.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>stellar</td>\n",
       "      <td>174189.0</td>\n",
       "      <td>112.917505</td>\n",
       "      <td>123.617706</td>\n",
       "      <td>0.963742</td>\n",
       "      <td>497.0</td>\n",
       "      <td>77.400000</td>\n",
       "      <td>295.900000</td>\n",
       "      <td>508161.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.320000e+04</td>\n",
       "      <td>4.189240e+04</td>\n",
       "      <td>471.500000</td>\n",
       "      <td>1638.800000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.425746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2021-04-25</td>\n",
       "      <td>stellar</td>\n",
       "      <td>174538.0</td>\n",
       "      <td>113.106640</td>\n",
       "      <td>123.931590</td>\n",
       "      <td>0.964728</td>\n",
       "      <td>497.0</td>\n",
       "      <td>78.900000</td>\n",
       "      <td>300.700000</td>\n",
       "      <td>509434.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.216667e+05</td>\n",
       "      <td>5.276517e+04</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>2412.333333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.416438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>stellar</td>\n",
       "      <td>174909.0</td>\n",
       "      <td>113.368209</td>\n",
       "      <td>123.002012</td>\n",
       "      <td>0.964366</td>\n",
       "      <td>497.0</td>\n",
       "      <td>55.900000</td>\n",
       "      <td>233.100000</td>\n",
       "      <td>510632.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.844286e+04</td>\n",
       "      <td>4.014940e+04</td>\n",
       "      <td>645.375000</td>\n",
       "      <td>1645.800000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.485610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>stellar</td>\n",
       "      <td>175329.0</td>\n",
       "      <td>113.951613</td>\n",
       "      <td>123.556452</td>\n",
       "      <td>0.964395</td>\n",
       "      <td>496.0</td>\n",
       "      <td>61.600000</td>\n",
       "      <td>249.100000</td>\n",
       "      <td>512006.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.511667e+04</td>\n",
       "      <td>4.251678e+04</td>\n",
       "      <td>498.833333</td>\n",
       "      <td>1790.555556</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.509479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>stellar</td>\n",
       "      <td>175677.0</td>\n",
       "      <td>113.953722</td>\n",
       "      <td>122.293763</td>\n",
       "      <td>0.965433</td>\n",
       "      <td>497.0</td>\n",
       "      <td>62.600000</td>\n",
       "      <td>260.100000</td>\n",
       "      <td>513429.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.034286e+04</td>\n",
       "      <td>4.068910e+04</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1683.700000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.497349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_scrape coin_name  r_subscribers  r_comments    r_upvotes  \\\n",
       "2    2021-03-09   bitcoin      2557418.0  190.953722  1351.696177   \n",
       "3    2021-03-10   bitcoin      2561723.0  192.705645  1384.280242   \n",
       "4    2021-03-11   bitcoin      2565734.0  194.002016  1391.931452   \n",
       "5    2021-03-12   bitcoin      2569574.0  197.231855  1419.247984   \n",
       "6    2021-03-13   bitcoin      2574583.0  199.645161  1462.635081   \n",
       "..          ...       ...            ...         ...          ...   \n",
       "756  2021-04-24   stellar       174189.0  112.917505   123.617706   \n",
       "757  2021-04-25   stellar       174538.0  113.106640   123.931590   \n",
       "758  2021-04-26   stellar       174909.0  113.368209   123.002012   \n",
       "759  2021-04-27   stellar       175329.0  113.951613   123.556452   \n",
       "760  2021-04-28   stellar       175677.0  113.953722   122.293763   \n",
       "\n",
       "     r_upvote_ratio  t_unique_posts  t_retweets  t_favorites  t_followers  \\\n",
       "2          0.925111           497.0  434.166667  2812.666667    1631642.0   \n",
       "3          0.926613           496.0  375.000000  2691.400000    1639941.4   \n",
       "4          0.927359           496.0  416.600000  2967.400000    1650183.0   \n",
       "5          0.929335           496.0  424.800000  2999.100000    1656158.0   \n",
       "6          0.928972           496.0  727.500000  4924.400000    1667004.0   \n",
       "..              ...             ...         ...          ...          ...   \n",
       "756        0.963742           497.0   77.400000   295.900000     508161.0   \n",
       "757        0.964728           497.0   78.900000   300.700000     509434.0   \n",
       "758        0.964366           497.0   55.900000   233.100000     510632.0   \n",
       "759        0.964395           496.0   61.600000   249.100000     512006.0   \n",
       "760        0.965433           497.0   62.600000   260.100000     513429.0   \n",
       "\n",
       "     t_unique_users  y_subscribers       y_views   y_comments      y_likes  \\\n",
       "2               6.0   1.845257e+06  9.898475e+05  5160.111111   833.700000   \n",
       "3              10.0   1.918453e+06  1.450209e+06  5807.250000   746.000000   \n",
       "4              10.0   1.920220e+06  1.487169e+06  3382.600000   768.333333   \n",
       "5              10.0   1.760500e+06  1.116006e+06  4232.400000   689.800000   \n",
       "6              10.0   1.613264e+06  1.144156e+06  3619.000000   670.900000   \n",
       "..              ...            ...           ...          ...          ...   \n",
       "756            10.0   7.320000e+04  4.189240e+04   471.500000  1638.800000   \n",
       "757            10.0   1.216667e+05  5.276517e+04   413.000000  2412.333333   \n",
       "758            10.0   6.844286e+04  4.014940e+04   645.375000  1645.800000   \n",
       "759            10.0   7.511667e+04  4.251678e+04   498.833333  1790.555556   \n",
       "760            10.0   7.034286e+04  4.068910e+04   335.000000  1683.700000   \n",
       "\n",
       "     y_unique_channels         price  \n",
       "2                 10.0  54824.117188  \n",
       "3                  6.0  56008.550781  \n",
       "4                  6.0  57805.121094  \n",
       "5                 10.0  57332.089844  \n",
       "6                 10.0  61243.085938  \n",
       "..                 ...           ...  \n",
       "756               10.0      0.425746  \n",
       "757                6.0      0.416438  \n",
       "758               10.0      0.485610  \n",
       "759                9.0      0.509479  \n",
       "760               10.0      0.497349  \n",
       "\n",
       "[544 rows x 17 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving\n",
    "df_final.to_csv('crypto_data_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
